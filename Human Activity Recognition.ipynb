{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500e3b9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "this version of pandas is incompatible with numpy < 1.15.4\nyour numpy version is 1.14.0.\nPlease upgrade numpy to >= 1.15.4 to use this pandas version",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7fe060cf3228>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aditi goel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0m_np_version_under1p16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0m_np_version_under1p17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aditi goel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_nlv\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;34m\"1.15.4\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     raise ImportError(\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;34m\"this version of pandas is incompatible with numpy < 1.15.4\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;34mf\"your numpy version is {_np_version}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;34m\"Please upgrade numpy to >= 1.15.4 to use this pandas version\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: this version of pandas is incompatible with numpy < 1.15.4\nyour numpy version is 1.14.0.\nPlease upgrade numpy to >= 1.15.4 to use this pandas version"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce0048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    df_tmp = pd.read_csv('DataSet/Participant_' + str(i+1) + '.csv', header=1)\n",
    "    df = pd.concat([df, df_tmp])\n",
    "\n",
    "# View top 5 rows of dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda881ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(len(df) * 0.8)\n",
    "train_data = df.iloc[:split_point, :]\n",
    "test_data = df.iloc[split_point:, :]\n",
    "\n",
    "print(\"Number of train spamples: \", len(train_data))\n",
    "print(\"Number of test spamples: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concat(data):\n",
    "    \n",
    "    # Select left pocket data\n",
    "    left_pocket = data.iloc[:,1:10]\n",
    "    \n",
    "    #Square root of sum of squares of accelerometer, linear acceleration and gyroscope data\n",
    "    left_pocket[\"MA\"] = np.sqrt(np.square(left_pocket['Ax']) + np.square(left_pocket['Ay']) + np.square(left_pocket['Az']))\n",
    "    left_pocket[\"ML\"] = np.sqrt(np.square(left_pocket['Lx']) + np.square(left_pocket['Ly']) + np.square(left_pocket['Lz']))\n",
    "    left_pocket[\"MG\"] = np.sqrt(np.square(left_pocket['Gx']) + np.square(left_pocket['Gy']) + np.square(left_pocket['Gz']))\n",
    "    \n",
    "\n",
    "    # Select right pocket data\n",
    "    right_pocket = data.iloc[:,15:24]\n",
    "    right_pocket.columns=['Ax', 'Ay', 'Az', 'Lx', 'Ly', 'Lz', 'Gx', 'Gy', 'Gz']\n",
    "    \n",
    "    #Square root of sum of squares of accelerometer, linear acceleration and gyroscope data\n",
    "    right_pocket[\"MA\"] = np.sqrt(np.square(right_pocket['Ax']) + np.square(right_pocket['Ay']) + np.square(right_pocket['Az']))\n",
    "    right_pocket[\"ML\"] = np.sqrt(np.square(right_pocket['Lx']) + np.square(right_pocket['Ly']) + np.square(right_pocket['Lz']))\n",
    "    right_pocket[\"MG\"] = np.sqrt(np.square(right_pocket['Gx']) + np.square(right_pocket['Gy']) + np.square(right_pocket['Gz']))\n",
    "\n",
    "    \n",
    "    # Extract labels \n",
    "    labels = data.iloc[:, 69] \n",
    "    labels = labels.to_frame()\n",
    "    labels.columns=['Activity_Label']\n",
    "    labels = pd.concat([labels]*2, ignore_index=True)\n",
    "    #replace typo 'upsatirs' with upstairs! \n",
    "    labels.loc[(labels['Activity_Label'] == 'upsatirs')] = 'upstairs'\n",
    "    \n",
    "    #Concatenate left pocket and right pocket data into a single data frame (we only use left pocket and right pocket data)\n",
    "    frames = [left_pocket, right_pocket]\n",
    "    df = pd.concat(frames)\n",
    "   \n",
    "    return df, labels\n",
    "\n",
    "# Generate input data and labels\n",
    "train_X, train_y = concat(train_data)\n",
    "test_X, test_y = concat(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaae14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TIME_STEPS = 100 #sliding window length\n",
    "STEP = 50 #Sliding window step size\n",
    "N_FEATURES = 12 \n",
    "\n",
    "def generate_sequence(x, y, n_time_steps, step):\n",
    "    \n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(x) - n_time_steps, step):\n",
    "        ax = x['Ax'].values[i: i + n_time_steps]\n",
    "        ay = x['Ay'].values[i: i + n_time_steps]\n",
    "        az = x['Az'].values[i: i + n_time_steps]\n",
    "\n",
    "        lx = x['Lx'].values[i: i + n_time_steps]\n",
    "        ly = x['Ly'].values[i: i + n_time_steps]\n",
    "        lz = x['Lz'].values[i: i + n_time_steps]\n",
    "        \n",
    "        gx = x['Gx'].values[i: i + n_time_steps]\n",
    "        gy = x['Gy'].values[i: i + n_time_steps]\n",
    "        gz = x['Gz'].values[i: i + n_time_steps]\n",
    "\n",
    "        MA = x['MA'].values[i: i + n_time_steps]\n",
    "        ML = x['ML'].values[i: i + n_time_steps]\n",
    "        MG = x['MG'].values[i: i + n_time_steps]\n",
    "       \n",
    "        label = stats.mode(y['Activity_Label'][i: i + n_time_steps])[0][0]\n",
    "        segments.append([ax, ay, az, lx, ly, lz, gx, gy, gz, MA, ML, MG])\n",
    "        labels.append(label)\n",
    "        \n",
    "    return segments, labels\n",
    "\n",
    "train_X, train_y = generate_sequence(train_X, train_y, N_TIME_STEPS, STEP)\n",
    "test_X, test_y = generate_sequence(test_X, test_y, N_TIME_STEPS, STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input segments and one-hot encode labels\n",
    "def reshape_segments(x, y, n_time_steps, n_features):\n",
    "    \n",
    "    x_reshaped = np.asarray(x, dtype= np.float32).reshape(-1, n_time_steps, n_features)\n",
    "    y_reshaped = np.asarray(pd.get_dummies(y), dtype = np.float32)\n",
    "    return x_reshaped, y_reshaped\n",
    "\n",
    "X_train, y_train = reshape_segments(train_X, train_y, N_TIME_STEPS, N_FEATURES)\n",
    "X_test, y_test = reshape_segments(test_X, test_y, N_TIME_STEPS, N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "N_CLASSES = 7\n",
    "N_HIDDEN_UNITS = 32\n",
    "L2 = 0.000001\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(N_HIDDEN_UNITS, return_sequences=True, input_shape=(N_TIME_STEPS, N_FEATURES), \n",
    "         kernel_initializer='orthogonal', kernel_regularizer=l2(L2), recurrent_regularizer=l2(L2),\n",
    "         bias_regularizer=l2(L2), name=\"LSTM_1\"),\n",
    "    Flatten(name='Flatten'),\n",
    "    Dense(N_HIDDEN_UNITS, activation='relu', kernel_regularizer=l2(L2), bias_regularizer=l2(L2), name=\"Dense_1\"),\n",
    "    Dense(N_CLASSES, activation='softmax', kernel_regularizer=l2(L2), bias_regularizer=l2(L2), name=\"Dense_2\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.RMSprop(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "callbacks= [ModelCheckpoint('model.h5', save_weights_only=False, save_best_only=True, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b679b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "N_EPOCHS = 30\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)\n",
    "\n",
    "LABELS = ['Biking' ,' Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "input_node_names= [\"lstm_1_input\"]\n",
    "output_node_name = \"Dense_2/Softmax\"\n",
    "MODEL_NAME = \"har_model\"\n",
    "\n",
    "tf.train.write_graph(K.get_session().graph_def, 'models', \\\n",
    "        MODEL_NAME + '_graph.pbtxt')\n",
    "saver = tf.train.Saver()\n",
    "saver.save(K.get_session(), 'models/' + MODEL_NAME + '.chkp')\n",
    "\n",
    "freeze_graph.freeze_graph('models/' + MODEL_NAME + '_graph.pbtxt', None, \\\n",
    "    False, 'models/' + MODEL_NAME + '.chkp', output_node_name, \\\n",
    "    \"save/restore_all\", \"save/Const:0\", \\\n",
    "    'models/frozen_' + MODEL_NAME + '.pb', True, \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
